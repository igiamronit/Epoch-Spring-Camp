{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "id": "Kab8tRJcQSxQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    [12.0, 1.5, 1, 'Wine'],\n",
        "    [5.0, 2.0, 0, 'Beer'],\n",
        "    [40.0, 0.0, 1, 'Whiskey'],\n",
        "    [13.5, 1.2, 1, 'Wine'],\n",
        "    [4.5, 1.8, 0, 'Beer'],\n",
        "    [38.0, 0.1, 1, 'Whiskey'],\n",
        "    [11.5, 1.7, 1, 'Wine'],\n",
        "    [5.5, 2.3, 0, 'Beer']\n",
        "]"
      ],
      "metadata": {
        "id": "ZlLj_dOzQbNP"
      },
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding:\n",
        "* Wine: $0$\n",
        "* Whiskey: $1$\n",
        "* Beer: $2$"
      ],
      "metadata": {
        "id": "3GxWzNIOSCAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([\n",
        "    [12.0, 1.5, 1],\n",
        "    [5.0, 2.0, 0],\n",
        "    [40.0, 0.0, 1],\n",
        "    [13.5, 1.2, 1],\n",
        "    [4.5, 1.8, 0],\n",
        "    [38.0, 0.1, 1],\n",
        "    [11.5, 1.7, 1],\n",
        "    [5.5, 2.3, 0]\n",
        "])\n",
        "y_train = np.array([0, 2, 1, 0, 2, 1, 0, 2])"
      ],
      "metadata": {
        "id": "vTl8nCQnQpOf"
      },
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gini impurity:\n",
        "$$Gini = 1- âˆ‘p_i^2$$"
      ],
      "metadata": {
        "id": "O6hqY7ZnSLgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gini_impurity(y):\n",
        "    classes, counts = np.unique(y, return_counts=True)\n",
        "    probs = counts / len(y)\n",
        "    return 1 - np.sum(probs ** 2)"
      ],
      "metadata": {
        "id": "ATycMYiPSjq2"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logic behind ```best_split(X, y)```\n",
        "\n",
        "This function finds the best feature and threshold to split the dataset, minimizing the weighted Gini impurity.\n",
        "\n",
        "---\n",
        "\n",
        "1. Initialize `best_gini` as $1.01$(as the worst value can be 1), `best_index`, and `best_threshold` to store the best split.\n",
        "2. Then loop through all the features and all its value.\n",
        "3. For each threshold:\n",
        "   - Split the data into left and right subsets based on the threshold.\n",
        "   - Calculate Gini impurity for both subsets.\n",
        "4. Compute the weighted Gini impurity for the split:\n",
        "   $$\n",
        "   \\text{Weighted Gini} = \\frac{n_{\\text{left}}}{n} \\cdot Gini_{\\text{left}} + \\frac{n_{\\text{right}}}{n} \\cdot Gini_{\\text{right}}\n",
        "   $$\n",
        "5. Update the best split if the current weighted Gini is smaller.\n",
        "6. Return the feature index and threshold that give the best split.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z8c91NGuSndp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def best_split(X, y):\n",
        "    best_gini = 1.01\n",
        "    best_index = None\n",
        "    best_threshold = None\n",
        "\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    for feature_index in range(n_features):\n",
        "        #print('This is feature ',feature_index)\n",
        "        thresholds = np.unique(X[:, feature_index])\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            left_mask = X[:, feature_index] <= threshold\n",
        "            right_mask = X[:, feature_index] > threshold\n",
        "\n",
        "            y_left = y[left_mask]\n",
        "            y_right = y[right_mask]\n",
        "\n",
        "            gini_left = gini_impurity(y_left)\n",
        "            gini_right = gini_impurity(y_right)\n",
        "\n",
        "            weighted_gini = (len(y_left) / len(y)) * gini_left + (len(y_right) / len(y)) * gini_right\n",
        "            #print(weighted_gini)\n",
        "\n",
        "            if weighted_gini <= best_gini:\n",
        "                best_gini = weighted_gini\n",
        "                best_index = feature_index\n",
        "                best_threshold = threshold\n",
        "                #print('This gini is selected',best_gini)\n",
        "\n",
        "    return best_index, best_threshold\n"
      ],
      "metadata": {
        "id": "qLeSro8EUKvz"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node :\n",
        "  def __init__(self,feature_index= None, threshold=None, left= None, right=None, value =None):\n",
        "    self.feature_index = feature_index\n",
        "    self.threshold = threshold\n",
        "    self.left = left\n",
        "    self.right = right\n",
        "    self.value = value"
      ],
      "metadata": {
        "id": "cyI9sOOtWxMp"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to build the decision tree ```build_tree```\n",
        "1. Get the values of number of samples, features, and number of unique labels\n",
        "2. We will then define our stopping conditions\n",
        "  * If number of labels becomes $1$.\n",
        "  * Number of samples becomes less than $2$.\n",
        "  * We have reached the ```max_depth```(5 here).\n",
        "3. We will then find the best split at current depth.\n",
        "4. We will then split the data into two parts\n",
        "  * ```left_mask``` is where feature value is less than or equal to threshold.\n",
        "  * ```right_mask``` is where feature value is more than threshold.\n",
        "5. We will then call ```build_tree``` recursively on the left half and the right half of the tree.  "
      ],
      "metadata": {
        "id": "Dz_KIPhiIyTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tree(X, y, max_depth=5, min_samples=2, depth=0):\n",
        "    num_samples, num_features = X.shape\n",
        "    unique_labels = np.unique(y)\n",
        "    num_labels = len(unique_labels)\n",
        "\n",
        "    # stopping conditions\n",
        "    if (num_labels == 1) or (num_samples < min_samples) or (depth >= max_depth):\n",
        "        majority_class = np.bincount(y).argmax()\n",
        "        return Node(value=majority_class)\n",
        "\n",
        "    feature_index, threshold = best_split(X, y)\n",
        "    #print(f\"Depth {depth}: Best split at feature {feature_index} with threshold {threshold}\")\n",
        "\n",
        "    left_mask = X[:, feature_index] <= threshold\n",
        "    right_mask = X[:, feature_index] > threshold\n",
        "\n",
        "    # building tree recursively\n",
        "    left = build_tree(X[left_mask], y[left_mask], max_depth, min_samples, depth + 1)\n",
        "    right = build_tree(X[right_mask], y[right_mask], max_depth, min_samples, depth + 1)\n",
        "\n",
        "    return Node(feature_index, threshold, left, right)\n"
      ],
      "metadata": {
        "id": "-yY-CKc8ZU7C"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to ```predict_sample```\n",
        "1. If it is a leaf node then return the value of class it is storing(prediction)\n",
        "2. If the value of required feature of the point is less than the threshold value then call the function recursively on the left child with same input point.\n",
        "3. Similarly if the value of required feature of the point is more than the threshold value then call the function recursively on the right child with same input point."
      ],
      "metadata": {
        "id": "zKhj2QUvL_Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sample(x, node):\n",
        "    if node.value is not None: #leaf node\n",
        "        return node.value\n",
        "\n",
        "    if x[node.feature_index] <= node.threshold:\n",
        "        return predict_sample(x, node.left)\n",
        "    else:\n",
        "        return predict_sample(x, node.right)"
      ],
      "metadata": {
        "id": "r3yWg4iAX0tb"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, tree):\n",
        "    return [predict_sample(x, tree) for x in X]"
      ],
      "metadata": {
        "id": "7L2-Qg3KgFt5"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = build_tree(X_train, y_train)\n",
        "\n",
        "test_data = np.array([\n",
        "    [6.0, 2.1, 0],   # Expected: Beer\n",
        "    [39.0, 0.05, 1], # Expected: Whiskey\n",
        "    [13.0, 1.3, 1]   # Expected: Wine\n",
        "])\n",
        "\n",
        "predictions = predict(test_data, tree)\n",
        "for prediction in predictions:\n",
        "  if(prediction == 0):\n",
        "    print('Wine')\n",
        "  if(prediction == 1):\n",
        "    print('Whiskey')\n",
        "  if(prediction == 2):\n",
        "    print('Beer')"
      ],
      "metadata": {
        "id": "QWt5ku4bdQHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "790572ef-f93c-45bc-da07-f799ee538158"
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beer\n",
            "Whiskey\n",
            "Wine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using ```print_tree``` function to print the decision tree\n",
        "\n",
        "1. **Leaf Node Check**: If the current node has a `value` (i.e., it's a leaf node), it prints a prediction (e.g., `Predict â†’ [class_label]`) and returns.\n",
        "2. **Decision Node**:\n",
        "   - Retrieves the feature name or index being used at this node to split the data.\n",
        "   - Prints the condition being checked at the current node (e.g., `If feature[0] <= 2.5:`).\n",
        "   - Recursively calls itself on the left child node, increasing indentation.\n",
        "   - Prints the `else` condition (i.e., if the feature is greater than the threshold).\n",
        "   - Recursively calls itself on the right child node, again with increased indentation.\n",
        "\n",
        "This function helps visualize the structure of a decision tree and understand the logic used for predictions.\n"
      ],
      "metadata": {
        "id": "AuD4C9uFPqtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_tree(node, feature_names=None, spacing=\"\"):\n",
        "    if node.value is not None: #leaf node\n",
        "        print(spacing + f\"Predict â†’ {node.value}\")\n",
        "        return\n",
        "\n",
        "    feature = f\"feature[{node.feature_index}]\" if feature_names is None else feature_names[node.feature_index]\n",
        "    print(spacing + f\"If {feature} <= {node.threshold:.3f}:\")\n",
        "\n",
        "    print_tree(node.left, feature_names, spacing + \"  \")\n",
        "    print(spacing + f\"Else (if {feature} > {node.threshold:.3f}):\")\n",
        "    print_tree(node.right, feature_names, spacing + \"  \")"
      ],
      "metadata": {
        "id": "tY4Tix3Dc12b"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_name = ['Alcohol Content', \"Sugar\", \"Color\"]\n",
        "print_tree(tree, features_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkPSZFUfc3Lw",
        "outputId": "9c1adbad-50e4-48f1-e999-d15ad2b306d3"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If Color <= 0.000:\n",
            "  Predict â†’ 2\n",
            "Else (if Color > 0.000):\n",
            "  If Sugar <= 0.100:\n",
            "    Predict â†’ 1\n",
            "  Else (if Sugar > 0.100):\n",
            "    Predict â†’ 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree Using Entropy:\n",
        "1. This section we will implement the decision tree using entropy instead of gini impurity.\n",
        "2. We define entropy as,\n",
        "  $$\n",
        "  Entropy = -âˆ‘p_i\\log_2(p_i)\n",
        "  $$\n",
        "  where $p_i \\ne 0$\n",
        "3. In the ```best_split_entropy``` function we just use entropy instead of gini to find the best split.\n",
        "4. Similarly in ```build_tree_entropy``` function we just use ```best_split_entropy``` instead of ```best_split``` to make the tree"
      ],
      "metadata": {
        "id": "CejWKTgHT8DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(y):\n",
        "  classes, counts = np.unique(y, return_counts=True)\n",
        "  probabilities = counts / counts.sum()\n",
        "  return -np.sum(probabilities * np.log2(probabilities, where=(probabilities != 0)))"
      ],
      "metadata": {
        "id": "czuKA7HjaIOD"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_split_entropy(X, y):\n",
        "    best_entropy = 100\n",
        "    best_index = None\n",
        "    best_threshold = None\n",
        "\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    for feature_index in range(n_features):\n",
        "        #print('This is feature ',feature_index)\n",
        "        thresholds = np.unique(X[:, feature_index])\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            left_mask = X[:, feature_index] <= threshold\n",
        "            right_mask = X[:, feature_index] > threshold\n",
        "\n",
        "            y_left = y[left_mask]\n",
        "            y_right = y[right_mask]\n",
        "\n",
        "            entropy_left = entropy(y_left)\n",
        "            entropy_right = entropy(y_right)\n",
        "\n",
        "            weighted_entropy = (len(y_left) / len(y)) * entropy_left + (len(y_right) / len(y)) * entropy_right\n",
        "\n",
        "\n",
        "            if weighted_entropy <= best_entropy:\n",
        "                best_entropy = weighted_entropy\n",
        "                best_index = feature_index\n",
        "                best_threshold = threshold\n",
        "\n",
        "    return best_index, best_threshold"
      ],
      "metadata": {
        "id": "osmufJzUbbrs"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tree_entropy(X, y, max_depth=5, min_samples=2, depth=0):\n",
        "    num_samples, num_features = X.shape\n",
        "    unique_labels = np.unique(y)\n",
        "    num_labels = len(unique_labels)\n",
        "\n",
        "    # stopping conditions\n",
        "    if (num_labels == 1) or (num_samples < min_samples) or (depth >= max_depth):\n",
        "        majority_class = np.bincount(y).argmax()\n",
        "        return Node(value=majority_class)\n",
        "\n",
        "    feature_index, threshold = best_split_entropy(X, y)\n",
        "    #print(f\"Depth {depth}: Best split at feature {feature_index} with threshold {threshold}\")\n",
        "\n",
        "    left_mask = X[:, feature_index] <= threshold\n",
        "    right_mask = X[:, feature_index] > threshold\n",
        "\n",
        "    # building tree recursively\n",
        "    left = build_tree(X[left_mask], y[left_mask], max_depth, min_samples, depth + 1)\n",
        "    right = build_tree(X[right_mask], y[right_mask], max_depth, min_samples, depth + 1)\n",
        "\n",
        "    return Node(feature_index, threshold, left, right)"
      ],
      "metadata": {
        "id": "LozhRp-yVYKs"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction using Entropy : We can see for the given test set we are getting same results from both Gini and Entropy."
      ],
      "metadata": {
        "id": "e6rji2lIVQKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_entropy = build_tree_entropy(X_train, y_train)\n",
        "\n",
        "test_data = np.array([\n",
        "    [6.0, 2.1, 0],   # Expected: Beer\n",
        "    [39.0, 0.05, 1], # Expected: Whiskey\n",
        "    [13.0, 1.3, 1]   # Expected: Wine\n",
        "])\n",
        "\n",
        "predictions = predict(test_data, tree)\n",
        "for prediction in predictions:\n",
        "  if(prediction == 0):\n",
        "    print('Wine')\n",
        "  if(prediction == 1):\n",
        "    print('Whiskey')\n",
        "  if(prediction == 2):\n",
        "    print('Beer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxrWhuyGSt99",
        "outputId": "53bda4c6-b90a-4de7-bb0f-976f17bddc7c"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beer\n",
            "Whiskey\n",
            "Wine\n"
          ]
        }
      ]
    }
  ]
}